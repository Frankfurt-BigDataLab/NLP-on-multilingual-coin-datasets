{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mDXQY6gRhiCY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@title ## Prepare environment\n",
        "#@markdown Execute the cells to load and set up the environment. \n",
        "#@markdown </br> You can do this by selecting Runtime -> Run all or by pressing CTRL+F9\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install -U spacy==2.3.7\n",
        "!pip3 install pickle5\n",
        "\n",
        "# Import \n",
        "from IPython.display import clear_output \n",
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import HTML, Button, HBox, VBox\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import sys\n",
        "import pathlib\n",
        "import base64\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from spacy import displacy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Define necessary paths\n",
        "src = \"nlp/\"\n",
        "storage = \"temp_storage/\"\n",
        "ner_path = src + \"cnt/trained_model/ner/\"\n",
        "\n",
        "# Download files\n",
        "if not os.path.exists(src):\n",
        "  !wget -O file.zip 'https://docs.google.com/uc?export=download&id=1dYLnIKts07SXxsyBo8xx_R1TgErYLj_w&confirm=t'\n",
        "  !unzip file.zip\n",
        "\n",
        "\n",
        "# Create a storage folder\n",
        "if not os.path.exists(storage):\n",
        "  os.mkdir(storage)\n",
        "  \n",
        "# Remove unecessary files\n",
        "if os.path.exists(ner_path+\".ipynb_checkpoints\"):\n",
        "  os.rmdir(ner_path+\".ipynb_checkpoints\")\n",
        "  \n",
        "# Imports from downloaded files\n",
        "sys.path.append(src)\n",
        "from cnt.model import load_ner_model_v2\n",
        "from cnt.model import load_pipeline, predict_re_single_sentence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Named Entity Recognition\n",
        "#@markdown You can select the language and use the trained model to predict the entered design. \n",
        "#@markdown </br> It is also possible to download the detected entities.\n",
        "#@markdown </br>\n",
        "#@markdown </br> [Provide feedback](https://forms.gle/EZSf8gvL8rjWpS6L6)\n",
        "\n",
        "\n",
        "# data\n",
        "example_list = [\"Head of Athena, right, wearing Corinthian helmet.\",\n",
        "                \"Laureate bust of Septimius Severus, right, wearing scale cuirass and paludamentum; gorgoneion on cuirass.\",\n",
        "                \"Silenus kneeling left, holding cantharus in his right hand and resting his left on his hip.\"] \n",
        "# Editable fields\n",
        "textfield = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Type something',\n",
        "    description='',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "\n",
        "# Buttons\n",
        "predict_button = widgets.Button(description=\"Predict\")\n",
        "buttonds = widgets.Button(description=\"Delete Session\")\n",
        "# Output fields\n",
        "output = widgets.Output()\n",
        "\n",
        "# Non editable fields\n",
        "text_textfield = widgets.HTML(\n",
        "    value=\"<b>Design: </b>\"\n",
        ")\n",
        "\n",
        "text_language = widgets.HTML(\n",
        "    value=\"<b>Select language: </b>\"\n",
        ")\n",
        "\n",
        "text_example = widgets.HTML(\n",
        "    value=\"<b>Examples: </b>\"\n",
        ")\n",
        "# Dropdowns\n",
        "drop = widgets.Dropdown(\n",
        "    options=os.listdir(ner_path),\n",
        "    disabled=False, continuous_update=True,layout={'width': 'max-content'},\n",
        "    value=\"english\"\n",
        ")\n",
        "\n",
        "example_dropdown = widgets.Dropdown(\n",
        "    options=example_list,\n",
        "    disabled=False, continuous_update=True,layout={'width': 'max-content'}\n",
        ")\n",
        "\n",
        "def load_language(language):\n",
        "\n",
        "  model_directory =  ner_path + drop.value+\"/\"\n",
        "\n",
        "  if language == \"english\":\n",
        "    model_name = \"english_cno\"\n",
        "\n",
        "  elif language== \"german\":\n",
        "    model_name = \"german_cno\"\n",
        "\n",
        "  return load_ner_model_v2(model_directory, model_name)\n",
        "\n",
        "\n",
        "# Predict function\n",
        "def apply_nlp(b):\n",
        "  \n",
        "\n",
        "\n",
        "  MODEL = load_language(drop.value)\n",
        "\n",
        "  sentence = textfield.value\n",
        "  if sentence == \"\":\n",
        "    sentence = example_dropdown.value\n",
        "\n",
        "  prediction = MODEL.predict_single_sentence_clear(sentence, as_doc=True)\n",
        "\n",
        "  colors = {'PERSON': 'mediumpurple','OBJECT': 'greenyellow', 'ANIMAL' : 'orange', 'PLANT': 'salmom', 'VERBS': 'skyblue'}\n",
        "  options = {'ent': ['PERSON', 'OBJECT', 'ANIMAL', 'PLANT'], 'colors': colors}\n",
        "\n",
        "  with output:\n",
        "    output.clear_output()\n",
        "    print()\n",
        "    display(sentence)\n",
        "    displacy.render(prediction,style='ent', jupyter=True, options=options)\n",
        "\n",
        "  create_csv(sentence)\n",
        "\n",
        "# create downloadable csv\n",
        "def create_csv(sentence):\n",
        "  MODEL = load_language(drop.value)\n",
        "\n",
        "  prediction1 = MODEL.predict_single_sentence(sentence)\n",
        "  prediction2 = MODEL.predict_single_sentence_clear(sentence, as_doc=False)\n",
        "\n",
        "  pred_dict = {}\n",
        "  for pred in range(len(prediction1)):\n",
        "    pred_dict[pred] = [prediction2[pred][0], prediction2[pred][1], prediction1[pred][0], prediction1[pred][1]]\n",
        "\n",
        "\n",
        "  df = pd.DataFrame.from_dict(pred_dict, orient=\"index\", columns=[\"Entity\", \"Class\", \"Start\", \"End\"]).to_csv(index=False)\n",
        "\n",
        "  filename = 'prediction.csv'\n",
        "  b64 = base64.b64encode(df.encode())\n",
        "  payload = b64.decode()\n",
        "\n",
        "  html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\"><button class=\"lm-Widget p-Widget jupyter-widgets jupyter-button widget-button\">Download Prediction</button></a>'\n",
        "  html = html.format(payload=payload, filename=filename)\n",
        "  with output:\n",
        "    display(HTML(html))\n",
        "\n",
        "\n",
        "\n",
        "# on_click functions\n",
        "predict_button.on_click(apply_nlp)\n",
        "\n",
        "# Display section\n",
        "display(HBox([text_textfield, textfield, HBox([text_example, example_dropdown])]))\n",
        "display(HBox([text_language, drop]))\n",
        "display(predict_button)\n",
        "display(output)\n",
        "\n",
        "text_example.add_class(\"left-spacing-class\")\n",
        "display(HTML(\n",
        "     \"<style>.left-spacing-class {margin-left: 150px;}</style>\"\n",
        "))\n"
      ],
      "metadata": {
        "id": "c5P91SHfp-VI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}